{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ec4d604-b6ab-46b6-a6bc-8815d8cc87dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9183a24c-bf2d-4a1d-84ec-bccaf2bae7a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7800, 0.2628, 0.1785])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "torch.float32\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3)\n",
    "print(x)\n",
    "y = torch.ones(2, 2)\n",
    "print(y)\n",
    "print(y.dtype)\n",
    "print(y.size())\n",
    "z = torch\n",
    "# The y.add_, y.mul_(Inplacement: modify y)\n",
    "# print(y[0, :]) print first row, print(y[:, 0]) print first column\n",
    "# print(y[1, 1]): a tensor with only one entry, use .item() to output real value\n",
    "# y.view() stack all the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bff2ed11-1e97-4371-85c9-0420b677c1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = b.numpy(), maps a tensor b to a numpy, but they shared same address!!!!!!!\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a) # convert a numpy array into a torch tensor\n",
    "#numpy can only handle CPU tensor\n",
    "# x = torch.ones(5, requires_grad=True) indicate that you will need the gradient for that \n",
    "# vector\n",
    "# y = x + 2 z = y * y * 2 z.backward() for the gradient\n",
    "#print(x.grad)\n",
    "# y = x.detach(), stop gradient depencence \n",
    "#weights.grad.zero_: Gradient will be accumulated, but the zero_give "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcf1f5b2-1748-4b5d-b737-c5fddede7d69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#autograd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as functional\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48c431f9-8ef9-42ad-8bf1-39c41c46e80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG11(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG11, self).__init__()\n",
    "        self.Conv1 = nn.Conv2d(1, 64, 3, stride=1, padding=1)\n",
    "        self.BN1 = nn.BatchNorm2d(64)\n",
    "        self.MaxPool = nn.MaxPool2d(2, 2)\n",
    "        self.Conv2 = nn.Conv2d(64, 128, 3, stride=1, padding=1)\n",
    "        self.BN2 = nn.BatchNorm2d(128)\n",
    "        self.Conv3 = nn.Conv2d(128, 256, 3, stride=1, padding=1)\n",
    "        self.BN3 = nn.BatchNorm2d(256)\n",
    "        self.Conv4 = nn.Conv2d(256, 256, 3, stride=1, padding=1)\n",
    "        self.BN4 = nn.BatchNorm2d(256)\n",
    "        self.Conv5 = nn.Conv2d(256, 512, 3, stride=1, padding=1)\n",
    "        self.BN5 = nn.BatchNorm2d(512)\n",
    "        self.Conv6 = nn.Conv2d(512, 512, 3, stride=1, padding=1)\n",
    "        self.BN6 = nn.BatchNorm2d(512)\n",
    "        self.Conv7 = nn.Conv2d(512, 512, 3, stride=1, padding=1)\n",
    "        self.BN7 = nn.BatchNorm2d(512)\n",
    "        self.Conv8 = nn.Conv2d(512, 512, 3, stride=1, padding=1)\n",
    "        self.BN8 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.FC1 = nn.Linear(512, 4096)\n",
    "        self.FC2 = nn.Linear(4096, 4096)\n",
    "        self.FC3 = nn.Linear(4096, 10)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.MaxPool(functional.relu(self.BN1(self.Conv1(x))))\n",
    "        output = self.MaxPool(functional.relu(self.BN2(self.Conv2(output))))\n",
    "        output = functional.relu(self.BN3(self.Conv3(output)))\n",
    "        output = self.MaxPool(functional.relu(self.BN4(self.Conv4(output))))\n",
    "        output = functional.relu(self.BN5(self.Conv5(output)))\n",
    "        output = self.MaxPool(functional.relu(self.BN6(self.Conv6(output))))\n",
    "        output = functional.relu(self.BN7(self.Conv7(output)))\n",
    "        output = self.MaxPool(functional.relu(self.BN8(self.Conv8(output))))\n",
    "        \n",
    "        output = output.view(-1, 512)\n",
    "        output = self.dropout(functional.relu(self.FC1(output)))\n",
    "        output = self.dropout(functional.relu(self.FC2(output)))\n",
    "        output = self.FC3(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f873fd0-5f72-4ffd-a3da-1f9f475b4c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = train_dataset = torchvision.datasets.MNIST(root='./A3/data', \n",
    "                                           train=True, \n",
    "                                           transform=resize_transform,  \n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./A3/data', \n",
    "                                          train=False, \n",
    "                                          transform=resize_transform)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = 6000,\n",
    "                                               shuffle = True)\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size = 10000,\n",
    "                                               shuffle = False)\n",
    "\n",
    "train_Loss_Compute_Loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = 60000,\n",
    "                                               shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf5006ee-8d60-4f3d-98c9-70641c0b8520",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training:\n",
    "num_epoch = 1\n",
    "model = VGG11()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "237c4670-a531-4662-bbf0-e96db0a8e011",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (38149116.py, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[20], line 17\u001b[0;36m\u001b[0m\n\u001b[0;31m    if i + 1\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader))\n",
    "\n",
    "n_total_steps = len(train_dataloader)\n",
    "test_accuracy = []\n",
    "training_accuracy = []\n",
    "test_loss = []\n",
    "training_loss = []\n",
    "for epoch in range(num_epoch):\n",
    "    for i, (images, labels) in enumerate(train_dataloader):\n",
    "        predicted_labels = model(images)\n",
    "        loss = criterion(predicted_labels, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print (f'Epoch [{epoch+1}/{num_epoch}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for (images, labels) in train_Loss_Compute_dataloader:\n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels)\n",
    "            train_loss.append(loss.item())\n",
    "            _, predicted_labels = Tensor.max(output.data, 1)\n",
    "            accuracy = (predicted_labels == labels).sum().item() / 60000\n",
    "            train_accuracy.append(accuracy)\n",
    "        \n",
    "        for (images, labels) in test_dataloader:\n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels)\n",
    "            test_loss.append(loss.item())\n",
    "            _, predicted_labels = Tensor.max(output.data, 1)\n",
    "            accuracy = (predicted_labels == labels).sum().item() / 10000\n",
    "            test_accuracy.append(accuracy)\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7b50645-11b1-41ff-bc85-19b0a396a565",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f722e22-a615-4e65-be2c-5aa85f88e614",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
